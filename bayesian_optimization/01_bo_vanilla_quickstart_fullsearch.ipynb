{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.constraints import Interval\n",
    "\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Standardize\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition import qLogExpectedImprovement\n",
    "from botorch.sampling.stochastic_samplers import StochasticSampler\n",
    "\n",
    "from helpers import (load_experiment_metadata, \n",
    "                    compute_nrmse_counts_all_edges, \n",
    "                    parse_loop_data_xml_to_pandas, \n",
    "                    create_taz_xml,\n",
    "                    simulate_od,\n",
    "                    od_xml_to_df,\n",
    "                    xml2df_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!Pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = \"/home/bench/Gitsrcs/origin_destination_bayes_opt\"\n",
    "# base_path = \"/Users/osorio/HEC/Research/Group/FacultyCollaborations/SeongjinChoi_UMN/Code_BO/origin_destination_bayes_opt-main\"\n",
    "base_path = \"/Users/chois/Gitsrcs/origin_destination_bayes_opt\"\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(base_path , 'config')\n",
    "print(f\"config_path: {config_path}\")\n",
    "\n",
    "config, sim_setup = load_experiment_metadata(config_path)\n",
    "\n",
    "network_name = sim_setup['network_name']\n",
    "model_name = sim_setup['model_name']\n",
    "\n",
    "network_path = Path(\"network\" , network_name)\n",
    "taz2edge_xml = Path(base_path, network_path, 'taz.xml')\n",
    "net_xml = Path(base_path, network_path, 'net.xml')\n",
    "fixed_routes = Path(base_path, network_path, 'routes.csv')\n",
    "file_gt_od = Path(base_path, network_path, 'od.xml')\n",
    "additional_xml = Path(base_path, network_path, 'additional.xml')\n",
    "\n",
    "out_path = f\"output/{network_name}_{model_name}\" \n",
    "Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gt_version_str = network_name           ## TODO : need to check if this is correct\n",
    "\n",
    "EDGE_OUT_STR = f'edge_data_{network_name}.xml'\n",
    "# suffix of simulation output edge file\n",
    "TRIPS2ODS_OUT_STR = 'trips.xml'\n",
    "SUMO_PATH = config[\"SUMO\"]\n",
    "\n",
    "sim_start_time = sim_setup['sim_start_time']\n",
    "sim_end_time = sim_setup['sim_end_time']\n",
    "sim_stat_freq_sec = sim_setup['sim_stat_freq_sec']\n",
    "od_duration_sec = sim_setup['od_duration_sec']\n",
    "\n",
    "n_init_search = sim_setup['n_init_search']\n",
    "\n",
    "NITER = sim_setup[\"BO_niter\"]\n",
    "BATCH_SIZE = sim_setup[\"BO_batch_size\"]\n",
    "NUM_RESTARTS = sim_setup[\"BO_num_restarts\"]\n",
    "RAW_SAMPLES = sim_setup[\"BO_raw_samples\"] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # taz2edge_xml = 'taz_new.xml'\n",
    "# # net_xml = 'SFO.net.xml'\n",
    "# # fixed_routes_xml = f'{base_path}/5hr_route_choice_set.csv'\n",
    "# # od_duration_seconds = 5*60 \n",
    "\n",
    "# # # duration of sample time for simulation output statistics\n",
    "# # simulation_stat_freq_sec = od_duration_seconds\n",
    "# # sim_end_time = od_duration_seconds\n",
    "# # additional_xml = f'additional.add_statfreq{od_duration_seconds}.xml'\n",
    "\n",
    "# # # suffix of simulation output edge file\n",
    "# # EDGE_OUT_STR = 'edge_data_SFO.xml'\n",
    "# # TRIPS2ODS_OUT_STR = 'trips.xml'\n",
    "# # SUMO_PATH = '/usr/local/opt/sumo/share/sumo'\n",
    "\n",
    "# od_duration_seconds = 30*60 \n",
    "\n",
    "# # duration of sample time for simulation output statistics\n",
    "# simulation_stat_freq_sec = od_duration_seconds\n",
    "# sim_end_time = od_duration_seconds\n",
    "\n",
    "# # TODO: it might be cleaner to replace this with a config file, i attached to my email an example. and one can define one config file per network. \n",
    "# network_name = \"quickstart\"\n",
    "# model_name = \"bo_vanilla\"\n",
    "\n",
    "# network_path = f\"network/{network_name}\"\n",
    "# taz2edge_xml = f\"{base_path}/{network_path}/taz.xml\"\n",
    "# net_xml = f\"{base_path}/{network_path}/net.xml\"\n",
    "# fixed_routes = f\"{base_path}/{network_path}/routes.csv\"\n",
    "# # od_xml = f\"{network_path}/od.xml\"       ## TODO : need to check if this is correct\n",
    "# file_gt_od = f\"{base_path}/{network_path}/od.xml\"      ## TODO : need to check if this is correct\n",
    "# # file_gt_edges                         ## TODO : need to check if this is necessary (not being used below)\n",
    "# additional_xml = f\"{base_path}/{network_path}/additional.xml\"\n",
    "# out_path = f\"output/{network_name}_{model_name}\"\n",
    "# out_path = f\"output/{network_name}_{model_name}\"       ## TODO : need to check if this is correct\n",
    "# # prefix_output = f\"{out_path}/out\"     ## TODO : need to check if this is correct\n",
    "# gt_version_str = network_name           ## TODO : need to check if this is correct\n",
    "\n",
    "# EDGE_OUT_STR = f'edge_data_{network_name}.xml'\n",
    "# # suffix of simulation output edge file\n",
    "# TRIPS2ODS_OUT_STR = 'trips.xml'\n",
    "# # TODO I changed this path for it to work for me.\n",
    "# SUMO_PATH = '/opt/homebrew/opt/sumo/share/sumo'\n",
    "# #SUMO_PATH = \"/usr/share/sumo\"\n",
    "\n",
    "# Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_version_str = 'v4'\n",
    "\n",
    "# gt v4:\n",
    "mean_od_val = 100\n",
    "num_ods = 10\n",
    "\n",
    "print('if you want to optimize them all (~86k) set num_ods as defined in commented line below')\n",
    "#num_ods = routes_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_xml = f'gt_od_{gt_version_str}.xml'\n",
    "# file_gt = f'{base_path}/gt_od_{gt_version_str}.xml'\n",
    "# file_gt_edges = f'{base_path}/gt_edges_{gt_version_str}.csv'\n",
    "# prefix_output_gt = f'gt_{gt_version_str}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GT OD\n",
    "print(\"Reading:\",file_gt_od)\n",
    "tree = ET.parse(file_gt_od)\n",
    "root = tree.getroot()\n",
    "gt_od_df =  xml2df_str(root, 'tazRelation')\n",
    "\n",
    "gt_od_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reading:\",fixed_routes)\n",
    "routes_df = pd.read_csv(fixed_routes, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_od_df = od_xml_to_df(file_gt_od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_od_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla BO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare parameter space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: let's put all import  statements at the top of the notebook\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "dtype = torch.double\n",
    "\n",
    "### Declare search space\n",
    "# dimensionality of input space\n",
    "\n",
    "dim_od = gt_od_df.shape[0]\n",
    "\n",
    "#bounds = torch.tensor([\n",
    "#    [ gt_od_df['count'].astype(float).min() - 2 for _ in range(dim_od)],\n",
    "#    [ gt_od_df['count'].astype(float).max() + 2 for _ in range(dim_od)]\n",
    "#], device=device, dtype=dtype) \n",
    "\n",
    "bounds = torch.tensor([\n",
    "    [ 0 for _ in range(dim_od)],\n",
    "    [ 2000 for _ in range(dim_od)]\n",
    "], device=device, dtype=dtype) \n",
    "\n",
    "\n",
    "bounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run GT simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_run_path =f'{out_path}'\n",
    "simulation_gt_run_path =f'{out_path}/ground_truth'\n",
    "Path(simulation_gt_run_path).mkdir(parents=True, exist_ok=True)\n",
    "prefix_output_gt = f'{simulation_gt_run_path}/sim'\n",
    "\n",
    "sim_edge_out_gt = f'{prefix_output_gt}_{EDGE_OUT_STR}'\n",
    "new_od_xml = f'{simulation_gt_run_path}/od.xml'\n",
    "\n",
    "base_od = gt_od_df.copy()\n",
    "gt_od_vals = gt_od_df['count'].astype(float).to_numpy()\n",
    "curr_od = gt_od_vals.copy()\n",
    "base_od['count'] = curr_od\n",
    "base_od = base_od.rename(columns={'fromTaz':'from', 'toTaz':'to'})        \n",
    "create_taz_xml(new_od_xml, base_od, od_duration_sec, base_path)\n",
    "\n",
    "print(base_od)\n",
    "\n",
    "# Run simulation\n",
    "\n",
    "simulate_od(new_od_xml, \n",
    "            prefix_output_gt, \n",
    "            base_path, \n",
    "            net_xml, \n",
    "            taz2edge_xml, \n",
    "            additional_xml,\n",
    "            routes_df,\n",
    "            sim_end_time,\n",
    "            TRIPS2ODS_OUT_STR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read output of GT simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_gt, _, _ = parse_loop_data_xml_to_pandas(base_path, sim_edge_out_gt, prefix_output_gt,SUMO_PATH)\n",
    "# picking at edges as GT edges\n",
    "num_gt_edges = df_edge_gt.shape[0]\n",
    "print(\"Number of GT edges:\",num_gt_edges)\n",
    "gt_edge_data = df_edge_gt\\\n",
    "    .sort_values(by=['interval_nVehContrib'], ascending=False)\\\n",
    "    .iloc[:num_gt_edges]\n",
    "\n",
    "# gt_edge_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full grid search\n",
    "n_full_search = 21\n",
    "candidates = []\n",
    "\n",
    "# print(dim_od)\n",
    "for i in range(dim_od):\n",
    "    candidates.append(torch.linspace(0,1,n_full_search))\n",
    "\n",
    "search_space = torch.meshgrid(candidates)\n",
    "search_space = torch.stack(search_space , 0)\n",
    "search_space.shape\n",
    "search_space = search_space.view(dim_od, -1)\n",
    "search_space = search_space.transpose(0,1)\n",
    "print(f\"search_space shape = {search_space.shape}\")\n",
    "\n",
    "# map the normalized into the original parameter space\n",
    "train_X0 = unnormalize(search_space, bounds)\n",
    "train_X0 = train_X0[1:,:]\n",
    "train_X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_epsilon_iter = 2\n",
    "ods_epsilon = []\n",
    "loss_all = []\n",
    "batch_data_i = []\n",
    "\n",
    "# Base OD which we will update their count entries\n",
    "base_od = gt_od_df.copy()\n",
    "gt_od_vals = gt_od_df['count'].astype(float).to_numpy()\n",
    "\n",
    "for i in tqdm(range(train_X0.shape[0])):\n",
    "      x = train_X0[i]\n",
    "#for i , x in enumerate(\n",
    "#      [[ 94.66438596,  91.97375804, 101.82277249, 112.44778006,\n",
    "#            105.33019264,  92.62166575,  99.8673423 ,  93.71928772,\n",
    "#            116.16658554,  94.79717515],\n",
    "#      [ 97.4, 114.9, 104.1, 100. , 109.1, 106.7,  87.8, 101.1, 113.9,109.4]]):\n",
    "      print(f\"########### OD: {i} ###########\")\n",
    "      print(x)\n",
    "      \n",
    "      Path(f'{simulation_run_path}/full_search').mkdir(parents=True, exist_ok=True)\n",
    "      new_od_xml = f'{simulation_run_path}/full_search/gt_od_{gt_version_str}_{i}.xml'\n",
    "      prefix_output_init = f'{simulation_run_path}/full_search/fullsearch_{i}'\n",
    "\n",
    "      # Generate OD\n",
    "      #curr_od = gt_od_vals.copy()\n",
    "      curr_od = np.array(x)\n",
    "\n",
    "      print(f'total expected GT demand: {np.sum(curr_od)}')\n",
    "\n",
    "      ###\n",
    "      # create OD xml file \n",
    "      ###\n",
    "      base_od['count'] = curr_od\n",
    "      # round to 1 decimal point\n",
    "      base_od['count'] = [round(elem, 1) for elem in base_od['count']]     \n",
    "      base_od = base_od.rename(columns={'fromTaz':'from', 'toTaz':'to'})        \n",
    "      create_taz_xml(new_od_xml, base_od, od_duration_sec, base_path)\n",
    "      ods_epsilon.append(curr_od)\n",
    "\n",
    "      # simulate gt od\n",
    "      simulate_od(new_od_xml, \n",
    "                  prefix_output_init, \n",
    "                  base_path, \n",
    "                  net_xml, \n",
    "                  taz2edge_xml, \n",
    "                  additional_xml, \n",
    "                  routes_df,\n",
    "                  sim_end_time,\n",
    "                  TRIPS2ODS_OUT_STR)\n",
    "\n",
    "      ## Compute loss\n",
    "      #prefix_output = f'full_search/sobol_{i}'\n",
    "      sim_edge_out = f'{base_path}/{prefix_output_init}_{EDGE_OUT_STR}'\n",
    "      print(sim_edge_out)\n",
    "      curr_loop_stats, _, _ = parse_loop_data_xml_to_pandas(base_path, sim_edge_out,prefix_output_init,SUMO_PATH)\n",
    "      curr_loss = compute_nrmse_counts_all_edges(gt_edge_data, curr_loop_stats)\n",
    "\n",
    "      loss_all.append(curr_loss)\n",
    "      print(f\"############## loss: {curr_loss} ##############\")\n",
    "\n",
    "      # Parse training data\n",
    "      df_curr = pd.DataFrame(curr_od.reshape(1,dim_od),\n",
    "                        columns = [f\"x_{i+1}\" for i in range(dim_od)])\n",
    "      df_curr['loss'] = curr_loss\n",
    "      batch_data_i.append(df_curr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_bo = pd.concat(batch_data_i)\n",
    "df_initial_bo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_run_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save initial dataset\n",
    "df_initial_bo.to_csv(f\"{simulation_run_path}/full_search/data_set_ods_0_2000.csv\",index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
