{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a vanilla (basic) Bayesian optimization algorithm to tackle an urban travel demand (i.e., origin-destination, OD) calibration problem. The traffic simulations are based on the SUMO simulator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMO configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount GDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working w/ colab rather than a jupyterlab notebook this drive mounting and sumo installation will need to be done every time you restart the runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install SUMO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sudo add-apt-repository -y ppa:sumo/stable\n",
    "# %sudo apt-get update\n",
    "# %sudo apt-get -y install sumo sumo-tools sumo-doc &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set sumo env vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variable\n",
    "import os\n",
    "import sys\n",
    "os.environ['SUMO_HOME'] = '/usr/share/sumo'\n",
    "os.environ['LIBSUMO_AS_TRACI'] = '1' #Optional: for a huge performance boost (~8x) with Libsumo (No GUI)\n",
    "\n",
    "if \"SUMO_HOME\" in os.environ:\n",
    "    tools = os.path.join(os.environ[\"SUMO_HOME\"], \"tools\")\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "#import traci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macros / utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/bench/Gitsrcs/origin_destination_bayes_opt\"\n",
    "\n",
    "# if base_path has a space in it, the sumo code will not work\n",
    "if ' ' in base_path:\n",
    "    raise ValueError(\"base_path should not contain spaces\")\n",
    "\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/bench/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/bench/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: lxml in /home/bench/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (5.3.0)\n",
      "Requirement already satisfied: matplotlib in /home/bench/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (3.8.3)\n",
      "Requirement already satisfied: torch in /home/bench/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.2.2+cu121)\n",
      "Requirement already satisfied: botorch in /home/bench/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.11.3)\n",
      "Requirement already satisfied: ipywidgets in /home/bench/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: sumolib in /home/bench/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.20.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/bench/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bench/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bench/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/bench/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/bench/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/bench/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 4)) (4.50.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bench/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 4)) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/bench/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/bench/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 4)) (10.3.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (12.1.3.1)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (11.4.5.107)\n",
      "Requirement already satisfied: fsspec in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (2.19.3)\n",
      "Requirement already satisfied: sympy in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
      "Requirement already satisfied: networkx in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: filelock in /home/bench/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (3.9.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/bench/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 5)) (12.1.105)\n",
      "Requirement already satisfied: mpmath<=1.3,>=0.19 in /home/bench/.local/lib/python3.10/site-packages (from botorch->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: scipy in /home/bench/.local/lib/python3.10/site-packages (from botorch->-r requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: gpytorch==1.12 in /home/bench/.local/lib/python3.10/site-packages (from botorch->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: linear-operator==0.5.2 in /home/bench/.local/lib/python3.10/site-packages (from botorch->-r requirements.txt (line 6)) (0.5.2)\n",
      "Requirement already satisfied: pyro-ppl>=1.8.4 in /home/bench/.local/lib/python3.10/site-packages (from botorch->-r requirements.txt (line 6)) (1.9.1)\n",
      "Requirement already satisfied: multipledispatch in /home/bench/.local/lib/python3.10/site-packages (from botorch->-r requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/bench/.local/lib/python3.10/site-packages (from gpytorch==1.12->botorch->-r requirements.txt (line 6)) (1.4.1.post1)\n",
      "Requirement already satisfied: jaxtyping>=0.2.9 in /home/bench/.local/lib/python3.10/site-packages (from linear-operator==0.5.2->botorch->-r requirements.txt (line 6)) (0.2.33)\n",
      "Requirement already satisfied: typeguard~=2.13.3 in /home/bench/.local/lib/python3.10/site-packages (from linear-operator==0.5.2->botorch->-r requirements.txt (line 6)) (2.13.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/bench/.local/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 7)) (8.23.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /home/bench/.local/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 7)) (3.0.11)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/bench/.local/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 7)) (5.14.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/bench/.local/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /home/bench/.local/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 7)) (4.0.11)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/bench/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/bench/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.1.6)\n",
      "Requirement already satisfied: stack-data in /home/bench/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/bench/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/bench/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/bench/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.17.2)\n",
      "Requirement already satisfied: decorator in /home/bench/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/bench/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (4.9.0)\n",
      "Requirement already satisfied: tqdm>=4.36 in /home/bench/.local/lib/python3.10/site-packages (from pyro-ppl>=1.8.4->botorch->-r requirements.txt (line 6)) (4.66.2)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /home/bench/.local/lib/python3.10/site-packages (from pyro-ppl>=1.8.4->botorch->-r requirements.txt (line 6)) (0.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/bench/.local/lib/python3.10/site-packages (from pyro-ppl>=1.8.4->botorch->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bench/.local/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/bench/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/bench/.local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/bench/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.2.13)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/bench/.local/lib/python3.10/site-packages (from scikit-learn->gpytorch==1.12->botorch->-r requirements.txt (line 6)) (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/bench/.local/lib/python3.10/site-packages (from scikit-learn->gpytorch==1.12->botorch->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: pure-eval in /home/bench/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/bench/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/bench/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 7)) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install missing packages\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition import qLogExpectedImprovement\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Standardize\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.sampling.stochastic_samplers import StochasticSampler\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "\n",
    "from bayesian_optimization.helpers import (load_kwargs_config, \n",
    "                    compute_nrmse_counts_all_edges, \n",
    "                    parse_loop_data_xml_to_pandas, \n",
    "                    create_taz_xml,\n",
    "                    simulate_od,\n",
    "                    od_xml_to_df,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BATCH_SIZE': 1,\n",
      " 'EDGE_OUT_STR': 'edge_data.xml',\n",
      " 'NITER': 100,\n",
      " 'NUM_RESTARTS': 5,\n",
      " 'RAW_SAMPLES': 32,\n",
      " 'SAMPLE_SHAPE': 128,\n",
      " 'SUMO_PATH': '/usr/share/sumo',\n",
      " 'TRIPS2ODS_OUT_STR': 'trips.xml',\n",
      " 'additional_xml': PosixPath('/home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/additional.xml'),\n",
      " 'edge_selection': PosixPath('/home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/edge_selection.txt'),\n",
      " 'file_gt_od': PosixPath('/home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/od.xml'),\n",
      " 'fixed_routes': PosixPath('/home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/routes.csv'),\n",
      " 'model_name': 'gridsearch',\n",
      " 'n_init_search': 30,\n",
      " 'net_xml': PosixPath('/home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/net.xml'),\n",
      " 'network_name': 'quickstart_underdetermined',\n",
      " 'network_path': PosixPath('network/quickstart_underdetermined'),\n",
      " 'od_duration_sec': 300,\n",
      " 'sim_end_time': 57600,\n",
      " 'sim_start_time': 54000,\n",
      " 'sim_stat_freq_sec': 300,\n",
      " 'simulation_run_path': 'output/quickstart_underdetermined_gridsearch',\n",
      " 'taz2edge_xml': PosixPath('/home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/taz.xml')}\n"
     ]
    }
   ],
   "source": [
    "config = load_kwargs_config(base_path, \"gridsearch\")\n",
    "Path(config[\"simulation_run_path\"]).mkdir(parents=True, exist_ok=True)\n",
    "pprint.pprint(dict(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create GT (ground truth) scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: /home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/od.xml\n",
      "total GT demand:  1400.0\n",
      "Reading: /home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/routes.csv\n",
      "Reading: /home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/edge_selection.txt\n"
     ]
    }
   ],
   "source": [
    "# Get Ground Truth OD + fixed routes\n",
    "print(f\"Reading: {config['file_gt_od']}\")\n",
    "gt_od_df = od_xml_to_df(config[\"file_gt_od\"])\n",
    "\n",
    "print(f\"Reading: {config['fixed_routes']}\")\n",
    "routes_df = pd.read_csv(config[\"fixed_routes\"], index_col=0)\n",
    "\n",
    "# if config[\"edge_selection\"] exists\n",
    "if \"edge_selection\" in config:\n",
    "    if not os.path.exists(config[\"edge_selection\"]):\n",
    "        edge_selection = None\n",
    "    else:\n",
    "        print(f\"Reading: {config['edge_selection']}\")\n",
    "        edge_selection = pd.read_csv(config[\"edge_selection\"], header=None)\n",
    "        edge_selection.columns = [\"edge_id\"]\n",
    "        edge_selection = edge_selection[\"edge_id\"].tolist()\n",
    "else:\n",
    "    edge_selection = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the GT scenario to obtain the GT traffic statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created  /home/bench/Gitsrcs/origin_destination_bayes_opt/output/quickstart_underdetermined_gridsearch/ground_truth/od.xml\n",
      "    from     to  count  data\n",
      "0  taz91  taz93  500.0  None\n",
      "1  taz91  taz94  900.0  None\n",
      "od2trips  --spread.uniform --taz-files /home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/taz.xml --tazrelation-files output/quickstart_underdetermined_gridsearch/ground_truth/od.xml -o /home/bench/Gitsrcs/origin_destination_bayes_opt/output/quickstart_underdetermined_gridsearch/ground_truth/sim_trips_beforeRteUpdates.xml\n",
      "Success.time 299.17\n",
      "###### Running SUMO #######\n",
      "Seed 0\n",
      "sumo --output-prefix output/quickstart_underdetermined_gridsearch/ground_truth/sim_ --ignore-route-errors=true --net-file=/home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/net.xml --routes=/home/bench/Gitsrcs/origin_destination_bayes_opt/output/quickstart_underdetermined_gridsearch/ground_truth/sim_trips.xml -b 0 -e 57600 --additional-files /home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/additional.xml --duration-log.statistics --xml-validation never --vehroutes routes.vehroutes.xml --verbose --no-warnings --mesosim true --seed 0\n",
      "Loading net-file from '/home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/net.xml' ... done (2ms).\n",
      "Loading additional-files from '/home/bench/Gitsrcs/origin_destination_bayes_opt/network/quickstart_underdetermined/additional.xml' ... done (1ms).\n",
      "Loading done.\n",
      "Simulation version 1.12.0 started with time: 0.00\n",
      "Step #57600.00 (0ms ?*RT. ?UPS, vehicles TOT 1400 ACT 0 BUF 0)                            \n",
      "Simulation ended at time: 57600.00\n",
      "Reason: The final simulation step has been reached.\n",
      "Performance: \n",
      " Duration: 0.20s\n",
      " Real time factor: 288000\n",
      " UPS: 2834505.000000\n",
      "Vehicles: \n",
      " Inserted: 1400\n",
      " Running: 0\n",
      " Waiting: 0\n",
      "Statistics (avg):\n",
      " RouteLength: 4320.34\n",
      " Speed: 10.69\n",
      " Duration: 404.93\n",
      " WaitingTime: 0.15\n",
      " TimeLoss: 88.49\n",
      " DepartDelay: 628.42\n",
      "\n",
      "DijkstraRouter answered 1400 queries and explored 10.37 edges on average.\n",
      "DijkstraRouter spent 0.00s answering queries (0.00ms on average).\n"
     ]
    }
   ],
   "source": [
    "simulation_gt_run_path =f'{config[\"simulation_run_path\"]}/ground_truth'\n",
    "prefix_output_gt = f'{simulation_gt_run_path}/sim'\n",
    "sim_edge_out_gt = f'{prefix_output_gt}_{config[\"EDGE_OUT_STR\"]}'\n",
    "new_od_xml = f'{simulation_gt_run_path}/od.xml'\n",
    "\n",
    "Path(simulation_gt_run_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "base_od = gt_od_df.copy()\n",
    "gt_od_vals = gt_od_df['count'].astype(float).to_numpy()\n",
    "curr_od = gt_od_vals.copy()\n",
    "base_od['count'] = curr_od\n",
    "base_od = base_od.rename(columns={'fromTaz':'from', 'toTaz':'to'})        \n",
    "create_taz_xml(new_od_xml, base_od, config[\"od_duration_sec\"], base_path)\n",
    "print(base_od)\n",
    "\n",
    "# Run simulation\n",
    "simulate_od(new_od_xml, \n",
    "            prefix_output_gt, \n",
    "            base_path, \n",
    "            config[\"net_xml\"], \n",
    "            config[\"taz2edge_xml\"], \n",
    "            config[\"additional_xml\"],\n",
    "            routes_df,\n",
    "            config[\"sim_end_time\"],\n",
    "            config[\"TRIPS2ODS_OUT_STR\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and process the GT simulation outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering edges to [['D2', 'D4', 'D7', 'D5']]\n",
      "Number of GT edges: 3\n",
      "output/quickstart_underdetermined_gridsearch/ground_truth/sim_edge_data.xml\n",
      "  edge_id  interval_nVehContrib  interval_harmonicMeanSpeed\n",
      "0      D2                1400.0                    8.591667\n",
      "2      D7                 900.0                   11.520000\n",
      "1      D5                 500.0                   11.076667\n"
     ]
    }
   ],
   "source": [
    "df_edge_gt, _, _ = parse_loop_data_xml_to_pandas(base_path, sim_edge_out_gt, prefix_output_gt, config[\"SUMO_PATH\"], edge_list=edge_selection)\n",
    "# picking at edges as GT edges\n",
    "num_gt_edges = df_edge_gt.shape[0]\n",
    "print(\"Number of GT edges:\",num_gt_edges)\n",
    "gt_edge_data = df_edge_gt\\\n",
    "    .sort_values(by=['interval_nVehContrib'], ascending=False)\\\n",
    "    .iloc[:num_gt_edges]\n",
    "\n",
    "print(sim_edge_out_gt)\n",
    "print(gt_edge_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian optimization utils / helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "dtype = torch.double\n",
    "\n",
    "dim_od = gt_od_df.shape[0]\n",
    "print(dim_od)\n",
    "\n",
    "bounds = torch.tensor([\n",
    "    [ 0 for _ in range(dim_od)],\n",
    "    [ 2000 for _ in range(dim_od)]\n",
    "], device=device, dtype=dtype) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and simulate a full-grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_space shape = torch.Size([40401, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   0.0000,   10.0000],\n",
       "        [   0.0000,   20.0000],\n",
       "        [   0.0000,   30.0000],\n",
       "        ...,\n",
       "        [2000.0000, 1980.0000],\n",
       "        [2000.0000, 1990.0000],\n",
       "        [2000.0000, 2000.0000]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full grid search\n",
    "n_full_search = 201\n",
    "candidates = []\n",
    "\n",
    "# print(dim_od)\n",
    "for i in range(dim_od):\n",
    "    candidates.append(torch.linspace(0,1,n_full_search))\n",
    "\n",
    "search_space = torch.meshgrid(candidates,indexing=\"ij\")\n",
    "search_space = torch.stack(search_space , 0)\n",
    "search_space.shape\n",
    "search_space = search_space.view(dim_od, -1)\n",
    "search_space = search_space.transpose(0,1)\n",
    "print(f\"search_space shape = {search_space.shape}\")\n",
    "search_space = search_space.to(device)\n",
    "\n",
    "# map the normalized into the original parameter space\n",
    "train_X0 = unnormalize(search_space, bounds)\n",
    "train_X0 = train_X0[1:,:]\n",
    "train_X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (40401) must match the existing size (40400) at non-singleton dimension 0.  Target sizes: [40401, 2].  Tensor sizes: [40400, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m loss_all \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m batch_data_i \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((search_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],dim_od\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(train_X0\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m----> 4\u001b[0m \u001b[43mbatch_data_i\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdim_od\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m train_X0\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Base OD which we will update their count entries\u001b[39;00m\n\u001b[1;32m      7\u001b[0m base_od \u001b[38;5;241m=\u001b[39m gt_od_df\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (40401) must match the existing size (40400) at non-singleton dimension 0.  Target sizes: [40401, 2].  Tensor sizes: [40400, 2]"
     ]
    }
   ],
   "source": [
    "ods_epsilon = []\n",
    "loss_all = []\n",
    "batch_data_i = torch.ones((search_space.shape[0],dim_od)).to(train_X0.device) * np.nan\n",
    "batch_data_i[:,0:dim_od] = train_X0\n",
    "\n",
    "# Base OD which we will update their count entries\n",
    "base_od = gt_od_df.copy()\n",
    "gt_od_vals = gt_od_df['count'].astype(float).to_numpy()\n",
    "\n",
    "for i , x in enumerate(train_X0.tolist()):\n",
    "      print(f\"########### OD: {i} ###########\")\n",
    "      print(x)\n",
    "      \n",
    "      simulation_run_path_grid =f'{config[\"simulation_run_path\"]}/full_search'\n",
    "      Path(simulation_run_path_grid).mkdir(parents=True, exist_ok=True)\n",
    "      \n",
    "      # new_od_xml = f\"{simulation_run_path_grid}/grid_od_{config['network_name']}_{i}.xml\"\n",
    "      # prefix_output_grid = f'{simulation_run_path_grid}/grid_{i}'\n",
    "\n",
    "      new_od_xml = f\"{simulation_run_path_grid}/grid_od_{config['network_name']}_temp.xml\"\n",
    "      prefix_output_grid = f'{simulation_run_path_grid}/grid_temp'\n",
    "\n",
    "      # Generate OD\n",
    "      #curr_od = gt_od_vals.copy()\n",
    "      curr_od = np.array(x)\n",
    "\n",
    "      print(f'total expected GT demand: {np.sum(curr_od)}')\n",
    "\n",
    "      ###\n",
    "      # create OD xml file \n",
    "      ###\n",
    "      base_od['count'] = curr_od\n",
    "      # round to 1 decimal point\n",
    "      base_od['count'] = [round(elem, 1) for elem in base_od['count']]     \n",
    "      base_od = base_od.rename(columns={'fromTaz':'from', 'toTaz':'to'})        \n",
    "      create_taz_xml(new_od_xml, base_od, config[\"od_duration_sec\"], base_path)\n",
    "      ods_epsilon.append(curr_od)\n",
    "\n",
    "      # simulate gridial search\n",
    "      simulate_od(new_od_xml, \n",
    "                  prefix_output_grid, \n",
    "                  base_path, \n",
    "                  config[\"net_xml\"], \n",
    "                  config[\"taz2edge_xml\"], \n",
    "                  config[\"additional_xml\"],\n",
    "                  routes_df,\n",
    "                  config[\"sim_end_time\"],\n",
    "                  config[\"TRIPS2ODS_OUT_STR\"])\n",
    "\n",
    "      ## Compute loss\n",
    "      #prefix_output = f'full_search/sobol_{i}'\n",
    "      sim_edge_out = f'{base_path}/{prefix_output_grid}_{config[\"EDGE_OUT_STR\"]}'\n",
    "      print(sim_edge_out)\n",
    "      curr_loop_stats, _, _ = parse_loop_data_xml_to_pandas(base_path, sim_edge_out,prefix_output_grid,config[\"SUMO_PATH\"], edge_list=edge_selection)\n",
    "      curr_loss = compute_nrmse_counts_all_edges(gt_edge_data, curr_loop_stats)\n",
    "\n",
    "      loss_all.append(curr_loss)\n",
    "      print(f\"############## loss: {curr_loss} ##############\")\n",
    "\n",
    "      # Parse training data\n",
    "      # df_curr = pd.DataFrame(curr_od.reshape(1,dim_od),\n",
    "                        # columns = [f\"x_{i+1}\" for i in range(dim_od)])\n",
    "      # df_curr['loss'] = curr_loss\n",
    "      # batch_data_i.append(df_curr)\n",
    "      batch_data_i[i,0:dim_od] = curr_od\n",
    "      batch_data_i[i,dim_od] = curr_loss\n",
    "\n",
    "      # Save numpy to csv\n",
    "      np.savetxt(f\"{simulation_run_path_grid}/data_set_ods_0_2000.csv\", batch_data_i, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
